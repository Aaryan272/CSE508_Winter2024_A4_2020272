{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*To clear the graphics memory*"
      ],
      "metadata": {
        "id": "anVBzUb6ex8K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRSwcCdy72Wb"
      },
      "outputs": [],
      "source": [
        "!pip install numba\n",
        "\n",
        "from numba import cuda\n",
        "device = cuda.get_current_device()\n",
        "device.reset()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wSPo3El4749q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch datasets"
      ],
      "metadata": {
        "id": "PU98tH8075LL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch] -U"
      ],
      "metadata": {
        "id": "wDMOF7Wa75V1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import torch\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
      ],
      "metadata": {
        "id": "e9ORF3_975gh"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Cleaning the dataset*"
      ],
      "metadata": {
        "id": "kr1CT_LZg-1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/IR_assignment4/Reviews.csv')"
      ],
      "metadata": {
        "id": "4znEaXMJfEnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Uxvh5IuKfEkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Remove duplicate entries\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# # Remove missing values\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "jKg74nc2fEh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "8ih_OsXKfEfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define function for text cleaning and preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Remove HTML tags\n",
        "    text = re.sub('<.*?>', '', text)\n",
        "    # Remove special characters and punctuation\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Tokenize text\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Lemmatize words\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    # Join tokens back into text\n",
        "    text = ' '.join(tokens)\n",
        "    return text\n",
        "\n",
        "# # Apply preprocessing to 'Text' column\n",
        "df['Clean_Text'] = df['Text'].apply(preprocess_text)\n",
        "\n",
        "# # Apply preprocessing to 'Summary' column\n",
        "df['Clean_Summary'] = df['Summary'].apply(preprocess_text)\n",
        "\n",
        "# # Display the cleaned and preprocessed data\n",
        "print(df[['Clean_Text', 'Clean_Summary']].head())"
      ],
      "metadata": {
        "id": "nYVvrv4-fEcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "aTsoDERgfEZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/drive/MyDrive/IR_assignment4/Clean_reviews.csv', index = False)"
      ],
      "metadata": {
        "id": "gnQ-sLvTfEWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "szi7h_1VfET0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/IR_assignment4/Clean_reviews.csv')"
      ],
      "metadata": {
        "id": "yl3uKjqQfEOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['Text', 'Summary'])"
      ],
      "metadata": {
        "id": "zVro_ekPfEGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/drive/MyDrive/IR_assignment4/Clean_reviews1.csv', index = False)"
      ],
      "metadata": {
        "id": "PmofQHmFfD4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/IR_assignment4/Clean_reviews1.csv')"
      ],
      "metadata": {
        "id": "AGfwHXBNgcNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Score', 'Time'])"
      ],
      "metadata": {
        "id": "sXqaKSbdgcFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/drive/MyDrive/IR_assignment4/Clean_reviews2.csv')"
      ],
      "metadata": {
        "id": "JvupCma5gcB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Initialize the GPT2 model and tokenizer*"
      ],
      "metadata": {
        "id": "aKeigGRahEJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtXrm3NC75tN",
        "outputId": "0854bded-0c7e-481c-ad30-95a73d6ab6aa"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50257, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Created custom dataset class along with encoded class*"
      ],
      "metadata": {
        "id": "s0_FqHdIhKk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "class ReviewsDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length=512, special_token='[PAD]'):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.dataframe = dataframe\n",
        "        self.max_length = max_length\n",
        "        self.special_token = special_token\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data_row = self.dataframe.iloc[idx]\n",
        "        text = data_row['Clean_Text']\n",
        "        summary = data_row['Clean_Summary']\n",
        "\n",
        "        if pd.isna(summary):\n",
        "            summary = self.special_token\n",
        "\n",
        "        encoded_text = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt',\n",
        "            return_attention_mask=True,\n",
        "        )\n",
        "        encoded_summary = self.tokenizer.encode_plus(\n",
        "            summary,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt',\n",
        "            return_attention_mask=True,\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'text':text,\n",
        "            'summary':summary,\n",
        "            'input_ids': encoded_text['input_ids'].flatten(),\n",
        "            'attention_mask': encoded_text['attention_mask'].flatten(),\n",
        "            'labels': encoded_summary['input_ids'].flatten(),\n",
        "        }\n"
      ],
      "metadata": {
        "id": "1mRna9DI756f"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/IR_assignment4/Clean_reviews2.csv')\n",
        "df = df[:10000]\n",
        "\n",
        "\n",
        "train_dataset, test_dataset = random_split(df, [int(0.75 * len(df)), len(df) - int(0.75 * len(df))])\n",
        "\n",
        "train_data = ReviewsDataset(df.iloc[train_dataset.indices], tokenizer, special_token='[PAD]')\n",
        "test_data = ReviewsDataset(df.iloc[test_dataset.indices], tokenizer, special_token='[PAD]')"
      ],
      "metadata": {
        "id": "ChcpdapJsH1l"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Model training along with different hyper parameters*"
      ],
      "metadata": {
        "id": "qBFzoXV4hX24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "\n",
        "\n",
        "# Define hyperparameters\n",
        "learning_rate = 5e-4\n",
        "batch_size = 8\n",
        "num_epochs = 5\n",
        "weight_decay = 0.01\n",
        "warmup_steps = 500\n",
        "optimizer = \"adamw\"  # AdamW optimizer\n",
        "dropout_rate = 0.1\n",
        "max_seq_length = 512\n",
        "\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results1',\n",
        "    num_train_epochs=num_epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=weight_decay,\n",
        "    logging_dir='./logs1',\n",
        "    logging_steps=10,\n",
        "    learning_rate=learning_rate,\n",
        "    logging_first_step=True,\n",
        "    overwrite_output_dir=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=test_data,\n",
        "\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "trainer.save_model('/content/drive/MyDrive/IR_assignment4/savedModel')\n",
        "tokenizer.save_pretrained('/content/drive/MyDrive/IR_assignment4/savedModel')"
      ],
      "metadata": {
        "id": "WKic30-176G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Loading the model*"
      ],
      "metadata": {
        "id": "_fUi7Ao7hfp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, GPT2Tokenizer, GPT2LMHeadModel\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load the saved tokenizer and model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"/content/drive/MyDrive/IR_assignment4/saved_model\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"/content/drive/MyDrive/IR_assignment4/saved_model\")\n"
      ],
      "metadata": {
        "id": "k5djeY2976b4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Text Summarisation using generated model*"
      ],
      "metadata": {
        "id": "dSkeqeTxhiwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n"
      ],
      "metadata": {
        "id": "_Ip4JSlM76sM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"\"\"\"\"\" + \"\\nTL;DR:\\n\"\n",
        "\n",
        "pipe_out = pipe(input_text, max_length=512, clean_up_tokenization_spaces=True)"
      ],
      "metadata": {
        "id": "KMG0NTCgGbkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "generated_summary = pipe_out[0]['generated_text']\n"
      ],
      "metadata": {
        "id": "C6qOw_ZOGcaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_summary"
      ],
      "metadata": {
        "id": "ZiLIYjUah025"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score"
      ],
      "metadata": {
        "id": "LluOZTjLGiBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "def Rouge_scores(given, generated):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    scores = scorer.score(given, generated)\n",
        "    Scores = {}\n",
        "    for key in scores:\n",
        "        keys = key.upper().replace(\"ROUGE\", \"ROUGE-\")\n",
        "        Scores[keys] = {\n",
        "            'Precision': round(scores[key].precision, 3),\n",
        "            'Recall': round(scores[key].recall, 3),\n",
        "            'F1-Score': round(scores[key].fmeasure, 3)\n",
        "        }\n",
        "\n",
        "    return Scores\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dE8riZmnGihq"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "given_summary = '''The Fender CD-60S Dreadnought Acoustic Guitar is a\n",
        "great instrument for beginners. It has a solid construction, produces a rich sound,\n",
        "and feels comfortable to play. However, some users have reported issues with the\n",
        "tuning stability.'''\n",
        "generated_summary = 'The Fender CD-60S Acoustic Guitar is suitable for beginners, but there are reported tuning stability issues.'\n"
      ],
      "metadata": {
        "id": "IU3aaP4KGjZx"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_results = Rouge_scores(given_summary, generated_summary)\n",
        "\n"
      ],
      "metadata": {
        "id": "x_x5sjX_Gj6S"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for score_type, values in rouge_results.items():\n",
        "\n",
        "    print(f\"{score_type}: Precision: {values['Precision']}, Recall: {values['Recall']}, F1-Score: {values['F1-Score']}\")"
      ],
      "metadata": {
        "id": "EWhjBRZclIrj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}